{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb4379cc-2830-4b7d-b997-b32e85b36ddb",
   "metadata": {},
   "source": [
    "# Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a7e1ca-81ca-430a-a7d0-ccdd85825869",
   "metadata": {},
   "source": [
    "Here are the assumptions required to use ANOVA:\n",
    "\n",
    "1. **Normality:** The data for each group should be normally distributed. This means that the data should be bell-shaped and symmetrical. If the data is not normally distributed, the results of the ANOVA may be invalid.\n",
    "\n",
    "2. **Homogeneity** of variances: The variances of the data for each group should be equal. This means that the spread of the data should be similar for each group. If the variances are not equal, the results of the ANOVA may be invalid.\n",
    "\n",
    "3. **Independence:** The data should be independent of each other. This means that the values of one data point should not be related to the values of any other data point. If the data is not independent, the results of the ANOVA may be invalid.\n",
    "\n",
    "Here are some examples of violations that could impact the validity of the results of an ANOVA:\n",
    "\n",
    "1. ***Non-normality:*** If the data is not normally distributed, the results of the ANOVA may be invalid. There are a number of ways to deal with non-normality, such as using a nonparametric test or transforming the data to make it more normal.\n",
    "\n",
    "2. ***Heterogeneity of variances:*** If the variances of the data for each group are not equal, the results of the ANOVA may be invalid. There are a number of ways to deal with heterogeneity of variances, such as using a Welch's ANOVA or a Brown-Forsythe test.\n",
    "\n",
    "3. ***Dependence:*** If the data is not independent, the results of the ANOVA may be invalid. There are a number of ways to deal with dependence, such as using a repeated measures ANOVA or a generalized linear model.\n",
    "\n",
    ">It is important to note that the assumptions of ANOVA are not always met.                                                                              \n",
    ">In these cases, it is important to carefully consider the impact of the violation on the results of the ANOVA. If the violation is likely to have a significant impact on the results, it may be necessary to use a different statistical test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8310b5-33fe-4e25-b3dd-af66b8686b4f",
   "metadata": {},
   "source": [
    "# Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dc3b34-b268-4b6e-8d88-899c5766508a",
   "metadata": {},
   "source": [
    "There are three types of ANOVA:\n",
    "\n",
    "**One-way ANOVA:** This type of ANOVA is used when there is only one independent variable, which has three or more levels (or groups). One-way ANOVA is used to determine if there are any significant differences between the means of the different levels/groups. \n",
    ">For example, one-way ANOVA can be used to compare the average weight loss among three different diet groups.\n",
    "\n",
    "**Two-way ANOVA:** This type of ANOVA is used when there are two independent variables, both of which have two or more levels. Two-way ANOVA is used to determine if there are any significant main effects (i.e., the effect of each independent variable on the dependent variable) and/or interaction effects (i.e., the combined effect of the two independent variables on the dependent variable). \n",
    ">For example, two-way ANOVA can be used to compare the average sales of two different products (product A and product B) in two different regions (North and South).\n",
    "\n",
    "**MANOVA (Multivariate Analysis of Variance):** This type of ANOVA is used when there are two or more dependent variables (i.e., outcome variables) and one or more independent variables. MANOVA is used to determine if there are any significant differences between the means of the dependent variables across the different levels of the independent variable. \n",
    ">For example, MANOVA can be used to compare the average scores on multiple personality traits (e.g., extroversion, agreeableness, neuroticism) between different age groups (young, middle-aged, and old).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d141dd57-5971-4424-a351-0da28eeb48fd",
   "metadata": {},
   "source": [
    "# Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26472e5b-3306-40a5-bd71-cd0e15b82a1a",
   "metadata": {},
   "source": [
    " **In ANOVA (Analysis of Variance), the partitioning of variance refers to the division of the total variance in the data into different components that can be attributed to specific sources of variation. Understanding this concept is important because it provides valuable insights into the factors that contribute to the observed differences in the data, helping to determine the significance of those factors and their effects.**\n",
    "\n",
    "The partitioning of variance in ANOVA involves dividing the total variance into two main components:\n",
    "\n",
    "> **Between-group variance:** This component of variance represents the differences among the group means. It measures the variation between the groups being compared in terms of the independent variable(s). A larger between-group variance suggests that the groups are more distinct from each other.\n",
    "\n",
    "> **Within-group variance:** This component of variance represents the differences within each group. It measures the variation within the groups and is typically attributed to random error or unexplained variability. A smaller within-group variance indicates that the data within each group are more homogeneous.\n",
    "\n",
    ">**Total variation = Variation explained by independent variable(s) + Variation not explained by independent variable(s)**                              \n",
    ">The variation explained by the independent variable(s) is referred to as the \"between-group\" variation, while the variation not explained by the independent variable(s) is referred to as the \"within-group\" variation.\n",
    "\n",
    "By comparing the magnitudes of the between-group and within-group variances, ANOVA determines if the observed differences among the groups are statistically significant. If the between-group variance is much larger than the within-group variance, it suggests that the independent variable(s) have a significant effect on the dependent variable.\n",
    "\n",
    "***Understanding the partitioning of variance helps in interpreting the results of ANOVA. It allows researchers to quantify the amount of variability in the data that can be explained by the independent variable(s) and to assess the relative importance of different sources of variation. This knowledge is crucial for drawing valid conclusions, making informed decisions, and understanding the factors influencing the outcome variable. Additionally, the partitioning of variance forms the basis for calculating effect sizes, which provide a standardized measure of the strength of the observed effects.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d104d7f1-90c1-459f-9d41-66b4fa5e5542",
   "metadata": {},
   "source": [
    "# Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39dd8738-6b40-45f9-9954-0591a60dc7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST = 133.33333333333331\n",
      "SSE = 103.33333333333333\n",
      "SSR = 29.999999999999986\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import scipy.stats as stats\n",
    "\n",
    "# create three sample groups\n",
    "group1 = [3, 5, 2, 6, 4]\n",
    "group2 = [7, 4, 6, 3, 5]\n",
    "group3 = [9, 11, 8, 10, 12]\n",
    "\n",
    "# concatenate the groups\n",
    "data = group1 + group2 + group3\n",
    "\n",
    "# calculate the mean of the data\n",
    "mean = sum(data) / len(data)\n",
    "\n",
    "# calculate the total sum of squares (SST)\n",
    "SST = sum([(x - mean)**2 for x in data])\n",
    "\n",
    "mean_group1=np.mean(group1)\n",
    "mean_group2=np.mean(group2)\n",
    "mean_group3=np.mean(group3)\n",
    "\n",
    "SSE=len(group1)*(mean_group1-mean)**2+\\\n",
    "    len(group2)*(mean_group2-mean)**2+\\\n",
    "    len(group3)*(mean_group3-mean)**2\n",
    "\n",
    "# calculate the residual sum of squares (SSR)\n",
    "SSR = SST - SSE\n",
    "\n",
    "print(\"SST =\", SST)\n",
    "print(\"SSE =\", SSE)\n",
    "print(\"SSR =\", SSR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d16c7a2-4144-47cb-a895-2a78f037e8aa",
   "metadata": {},
   "source": [
    "# Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08cd0714-b8de-46b6-afde-98a30c097396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Effect of Factor 1: 4.000000000000009\n",
      "Main Effect of Factor 2: 16.666666666666657\n",
      "Interaction Effect: 1.0000000000000018\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Sample data for two independent variables (factors)\n",
    "factor1 = np.array([1, 1, 2, 2, 3, 3])\n",
    "factor2 = np.array([1, 2, 1, 2, 1, 2])\n",
    "\n",
    "# Dependent variable data\n",
    "dependent_var = np.array([3, 5, 2, 6, 4, 8])\n",
    "\n",
    "# Create a DataFrame with the data\n",
    "data = {'dependent_var': dependent_var, 'factor1': factor1, 'factor2': factor2}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('dependent_var ~ factor1 + factor2 + factor1:factor2', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Extract the main effects and interaction effect\n",
    "main_effect_factor1 = anova_table.loc['factor1', 'sum_sq']\n",
    "main_effect_factor2 = anova_table.loc['factor2', 'sum_sq']\n",
    "interaction_effect = anova_table.loc['factor1:factor2', 'sum_sq']\n",
    "\n",
    "# Print the results\n",
    "print(\"Main Effect of Factor 1:\", main_effect_factor1)\n",
    "print(\"Main Effect of Factor 2:\", main_effect_factor2)\n",
    "print(\"Interaction Effect:\", interaction_effect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8344efd9-c026-4345-9a4c-ecc26a117b84",
   "metadata": {},
   "source": [
    "# Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. What can you conclude about the differences between the groups, and how would you interpret these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7a190e-a6b4-45df-8646-aa24c62839e1",
   "metadata": {},
   "source": [
    "Based on the given information from the one-way ANOVA, where the obtained F-statistic is 5.23 and the p-value is 0.02, we can draw the following conclusions:\n",
    "\n",
    "- **Significance of the F-statistic:** The F-statistic compares the variation between groups to the variation within groups. A higher F-statistic suggests larger differences between the groups. In this case, the obtained F-statistic of 5.23 indicates that there are some differences between the groups.\n",
    "\n",
    "- **Significance of the p-value:** The p-value indicates the probability of obtaining the observed results (or more extreme) if there were no real differences between the groups. A lower p-value suggests stronger evidence against the null hypothesis of no differences. In this case, the p-value of 0.02 is below the typical significance level of 0.05, indicating that there is sufficient evidence to reject the null hypothesis.\n",
    "\n",
    "***Interpretation: Based on these results, we can conclude that there are statistically significant differences between the groups being compared. The specific interpretation will depend on the context and the nature of the data being analyzed. It indicates that at least one of the groups differs from the others in terms of the variable being measured. However, it does not provide information about which particular group(s) differ. Further post-hoc tests or additional analysis would be needed to determine the specific group differences.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ed7a80-077e-46cc-8ca7-33468aadd4ad",
   "metadata": {},
   "source": [
    "# Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8583ad-8ae4-4244-a44b-87ffee121af9",
   "metadata": {},
   "source": [
    "Handling missing data in a repeated measures ANOVA requires careful consideration, as different methods can lead to different consequences. Here are some approaches to handling missing data and their potential consequences:\n",
    "\n",
    "**Complete Case Analysis (CCA):** This method involves excluding cases with missing data, resulting in a reduced sample size. The consequence is reduced statistical power and potential bias if the missing data are not random, leading to less accurate estimates and potentially biased results.\n",
    "\n",
    "**Pairwise Deletion:** This approach involves analyzing only available data for each pair of variables, allowing for varying sample sizes across comparisons. However, this can lead to imprecise estimates and biased results if the missing data are not missing completely at random (MCAR). It can also affect the interpretation of the results due to the dependency between the variables.\n",
    "\n",
    "**Imputation Methods:** Imputation involves replacing missing values with estimated values based on observed data. Common imputation methods include mean imputation, regression imputation, or multiple imputation. The consequences of imputation depend on the assumptions made and the quality of the imputation model. If the imputation model is misspecified or the imputation assumptions are violated, the estimates may be biased, and the standard errors may be underestimated.\n",
    "\n",
    "**Model-Based Methods:** These methods utilize advanced techniques such as maximum likelihood estimation or mixed-effects models to handle missing data. These approaches can provide valid estimates under certain assumptions, such as missing at random (MAR) or ignorable nonresponse. However, the assumptions must be carefully evaluated and justified to ensure valid inferences.\n",
    "\n",
    "In summary, the consequences of using different methods to handle missing data in a repeated measures ANOVA include reduced statistical power, biased estimates, imprecise results, and potentially incorrect conclusions. It is important to carefully assess the missing data mechanism and choose an appropriate method that aligns with the assumptions and goals of the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb10ef2-862b-4adc-965d-5c69af0a7a2a",
   "metadata": {},
   "source": [
    "# Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287920e2-11af-4c47-911c-5f536e31b53f",
   "metadata": {},
   "source": [
    "Post-hoc tests are used after ANOVA to make pairwise comparisons between groups when the overall ANOVA result is statistically significant. The purpose of post-hoc tests is to determine which specific groups differ from each other and to control for the familywise error rate, which is the probability of making at least one Type I error (false positive) across all the pairwise comparisons. Here are some common post-hoc tests used after ANOVA, along with an example of a situation where each one might be necessary:\n",
    "\n",
    "1. **Tukey's HSD (honestly significant difference) test:** This test is a conservative post-hoc test that is commonly used when the sample sizes are equal across groups. It controls for the familywise error rate by adjusting the significance level for each pairwise comparison. For example, if we have four groups (A, B, C, D), and the overall ANOVA result is significant, we might use Tukey's HSD test to determine which specific groups differ from each other. If the test shows that group A is significantly different from group B and group C, but not group D, we can conclude that group A is significantly different from groups B and C, but not group D.\n",
    "\n",
    "2. **Bonferroni correction:** This test is a simple and commonly used method to adjust the significance level for each pairwise comparison. It divides the significance level (usually 0.05) by the number of comparisons being made. For example, if we have four groups (A, B, C, D), and the overall ANOVA result is significant, we might use the Bonferroni correction to determine which specific groups differ from each other. If the test shows that group A is significantly different from group B, group C, and group D, we can conclude that group A is significantly different from all the other groups.\n",
    "\n",
    "3. **Dunnett's test:** This test is used when we have one control group and several treatment groups. It compares each treatment group to the control group, while controlling for the overall familywise error rate. For example, if we have one control group and three treatment groups (A, B, C), and the overall ANOVA result is significant, we might use Dunnett's test to determine which specific treatment groups differ from the control group. If the test shows that group A is significantly different from the control group, but groups B and C are not significantly different from the control group, we can conclude that group A is significantly different from the control group, but groups B and C are not.\n",
    "\n",
    "4. **Scheffe's test:** This test is a conservative post-hoc test that is used when the sample sizes are unequal across groups. It controls for the familywise error rate by adjusting the significance level for each pairwise comparison. For example, if we have four groups (A, B, C, D), and the overall ANOVA result is significant, we might use Scheffe's test to determine which specific groups differ from each other. If the test shows that group A is significantly different from group B and group C, but not group D, we can conclude that group A is significantly different from groups B and C, but not group D."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a77ea2-bdd5-4f79-9a83-ef5cbb0ebb1c",
   "metadata": {},
   "source": [
    "# Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e16b3e86-49d7-4024-bec4-96ed15302164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3761892269365994\n",
      "0.255795216474792\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Sample data\n",
    "diet_A = [2, 3, 4, 3, 5, 4, 3, 2, 1, 2, 3, 2, 1, 2, 3, 4, 3, 2, 3, 4,\n",
    "          5, 4, 3, 2, 3, 4, 5, 4, 3, 2, 3, 4, 5, 4, 3, 2, 3, 4, 5, 4,\n",
    "          3, 2, 3, 4, 5, 4, 3, 2, 3, 4]\n",
    "diet_B = [3, 4, 5, 4, 3, 2, 3, 4, 5, 4, 3, 2, 3, 4, 5, 4, 3, 2, 3, 4,\n",
    "          5, 4, 3, 2, 3, 4, 5, 4, 3, 2, 3, 4, 5, 4, 3, 2, 3, 4, 5, 4,\n",
    "          3, 2, 3, 4, 5, 4, 3, 2, 3, 4]\n",
    "diet_C = [4, 5, 4, 3, 2, 3, 4, 5, 4, 3, 2, 3, 4, 5, 4, 3, 2, 3, 4, 5,\n",
    "          4, 3, 2, 3, 4, 5, 4, 3, 2, 3, 4, 5, 4, 3, 2, 3, 4, 5, 4, 3,\n",
    "          2, 3, 4, 5, 4, 3, 2, 3, 4]\n",
    "\n",
    "# One-way ANOVA\n",
    "f_statistic , p_value  =stats.f_oneway(diet_A,diet_B,diet_C)\n",
    "\n",
    "print(f_statistic)\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2d0c7a-3bb0-4444-9f04-14ef99371431",
   "metadata": {},
   "source": [
    "# Q10. A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs.experienced).\n",
    "Report the F-statistics and p-values, and interpret the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "074f908f-3d0d-4fde-a292-393a957e7a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main effect of software (F = 0.38, p = 0.716)\n",
      "Main effect of experience (F = 0.00, p = 1.000)\n",
      "Interaction effect (F = 0.00, p = 1.000)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "data = {\n",
    "    'software': ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C'],\n",
    "    'experience': ['Novice', 'Experienced', 'Novice', 'Experienced', 'Novice', 'Experienced', 'Novice', 'Experienced', 'Novice'],\n",
    "    'time': [10, 12, 14, 9, 11, 13, 8, 10, 12]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "model = ols('time ~ software * experience', data=df).fit()\n",
    "\n",
    "anova_table = anova_lm(model, type=2)\n",
    "\n",
    "f_software = anova_table['F'][0]\n",
    "p_software = anova_table['PR(>F)'][0]\n",
    "f_experience = anova_table['F'][1]\n",
    "p_experience = anova_table['PR(>F)'][1]\n",
    "f_interaction = anova_table['F'][2]\n",
    "p_interaction = anova_table['PR(>F)'][2]\n",
    "\n",
    "print(f\"Main effect of software (F = {f_software:.2f}, p = {p_software:.3f})\")\n",
    "print(f\"Main effect of experience (F = {f_experience:.2f}, p = {p_experience:.3f})\")\n",
    "print(f\"Interaction effect (F = {f_interaction:.2f}, p = {p_interaction:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1032533a-379c-4cd5-96a9-786eb3623517",
   "metadata": {},
   "source": [
    "# Q11. An educational researcher is interested in whether a new teaching method improves student test scores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a two-sample t-test using Python to determine if there are any significant differences in test scores between the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "169adf32-50f3-47dd-9d0f-777a3d3574c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two sample t test results : t=-1.72 , p=0.103\n",
      "post hoc test results : t=-1.72 , p=0.103\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from scipy import stats \n",
    "\n",
    "control_scores = [80, 85, 78, 92, 88, 75, 82, 79, 86, 90]\n",
    "\n",
    "experimental_scores = [88, 92, 95, 82, 79, 86, 90, 85, 91, 87]\n",
    "\n",
    "t_statistic , p_value=stats.ttest_ind(control_scores , experimental_scores)\n",
    "\n",
    "print(f\"two sample t test results : t={t_statistic:.2f} , p={p_value:.3f}\")\n",
    "\n",
    "pairwise_t_statistic , pairwise_p_value = stats.ttest_ind(control_scores , experimental_scores)\n",
    "\n",
    "print(f\"post hoc test results : t={pairwise_t_statistic:.2f} , p={pairwise_p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761d20cb-68c1-43c4-bb89-72318c46479f",
   "metadata": {},
   "source": [
    "# Q12. A researcher wants to know if there are any significant differences in the average daily sales of three retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store on those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a post-hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98c42fc3-25e9-4e54-9fa9-7dc62c6a8ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-way repeated measures ANOVA results: F = -4.86, p = 1.000\n",
      "Post hoc test (Tukey's HSD) results:\n",
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05\n",
      "==================================================\n",
      "group1 group2 meandiff p-adj  lower  upper  reject\n",
      "--------------------------------------------------\n",
      "     A      B      0.0   1.0 -5.3308 5.3308  False\n",
      "     A      C      0.0   1.0 -5.3308 5.3308  False\n",
      "     B      C      0.0   1.0 -5.3308 5.3308  False\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Create a DataFrame with the sales data\n",
    "data = {\n",
    "    'Day': list(range(30)) * 3,\n",
    "    'Store': ['A'] * 30 + ['B'] * 30 + ['C'] * 30,\n",
    "    'Sales': [100, 110, 95, 105, 115, 100, 120, 115, 110, 105, 115, 120, 125, 110, 105,\n",
    "              120, 115, 110, 100, 105, 115, 120, 125, 130, 115, 120, 115, 110, 105, 100] * 3\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Perform repeated measures ANOVA\n",
    "aov = AnovaRM(df, 'Sales', 'Day', within=['Store']).fit()\n",
    "\n",
    "# Extract the F-value and p-value\n",
    "f_value = aov.anova_table['F Value'][0]\n",
    "p_value = aov.anova_table['Pr > F'][0]\n",
    "\n",
    "print(f\"One-way repeated measures ANOVA results: F = {f_value:.2f}, p = {p_value:.3f}\")\n",
    "\n",
    "# Perform post hoc test (Tukey's HSD)\n",
    "posthoc = pairwise_tukeyhsd(df['Sales'], df['Store'], alpha=0.05)\n",
    "\n",
    "print(\"Post hoc test (Tukey's HSD) results:\")\n",
    "print(posthoc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
